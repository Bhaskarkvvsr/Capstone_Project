{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revolut FinCrime Challenge: Data Analysis\n",
    "\n",
    "There will be a notebook for each one of the Machine Learning Pipeline steps:\n",
    "\n",
    "1. Data Analysis\n",
    "2. Feature Engineering\n",
    "3. Feature Selection\n",
    "4. Model Building\n",
    "\n",
    "**This is the notebook for step 1: Data Analysis**\n",
    "\n",
    "\n",
    "## Predicting Fradulent transactions\n",
    "\n",
    "The aim of the project is to build a machine learning model to find the fraudsters and take appropriate actions.\n",
    "\n",
    "![SegmentLocal](fraud.gif \"segment\")\n",
    "\n",
    "### Why is this important? \n",
    "\n",
    "Fraudsters can use our App to steal the other people's money from outside into an account via Top-Up's. So finding them and blocking them is very necessary.\n",
    "\n",
    "\n",
    "**We will analyse the datasets to identify:**\n",
    "\n",
    "1. [Missing values](#missing)<br>\n",
    "2. [Numerical variables](#numvar)<br>\n",
    "3. [Temporal variables](#temvar)<br>\n",
    "4. [Categorical variables](#catvar)<br>\n",
    "7. [Cardinality of the categorical variables](#cardi)<br>\n",
    "8. [Rare Labels](#rarelab)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 90\n",
    "% matplotlib inline\n",
    "\n",
    "# to display all the columns of the dataframe in the notebook\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "# to ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "from itertools import cycle,islice\n",
    "%precision %.2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_transactions = pd.read_csv('../data/transactions.csv')\n",
    "df_users = pd.read_csv('../data/users.csv')\n",
    "df_fraudsters = pd.read_csv('../data/fraudsters.csv')\n",
    "\n",
    "# Rows and Columns in the Datasets\n",
    "print(df_transactions.shape)\n",
    "print(df_users.shape)\n",
    "print(df_fraudsters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data\n",
    "df_fraudsters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the names of the columns to lower case\n",
    "df_transactions.columns = map(str.lower, df_transactions.columns)\n",
    "df_users.columns = map(str.lower, df_users.columns)\n",
    "df_fraudsters.columns = map(str.lower, df_fraudsters.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the column names\n",
    "df_transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions = df_transactions.merge(df_users,how='left',left_on='user_id',right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns\n",
    "df_user_transactions.rename({'id_x': 'transaction_id', 'created_date_x': 'transaction_date','created_date_y':'registered_date'}, axis=1, inplace=True)\n",
    "df_user_transactions.drop(['id_y'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the datatypes of temporal columns to datatime.\n",
    "df_user_transactions[[\"transaction_date\", \"registered_date\", \"birth_date\"]] = df_user_transactions[[\"transaction_date\", \"registered_date\", \"birth_date\"]].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions[[\"transaction_date\", \"registered_date\", \"birth_date\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the target variable 'is_fraud' by looking for the id's in the fraudsters table.\n",
    "df_user_transactions['is_fraud'] = 0\n",
    "df_fraudsters['is_fraud'] = 1\n",
    "\n",
    "df_user_transactions['is_fraud'] = df_user_transactions['user_id'].isin(df_fraudsters['user_id'])\n",
    "df_user_transactions['is_fraud'][df_user_transactions['is_fraud'] == 1] = 1\n",
    "df_user_transactions['is_fraud'] = df_user_transactions['is_fraud'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "<a id=\"missing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the variables that contain missing values\n",
    "df_user_transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Variables\n",
    "<a id=\"numvar\"></a>\n",
    "\n",
    "Let's go ahead and find the distribution of the continuous variables. We will consider continuous all those that are not temporal or discrete variables in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = [var for var in df_user_transactions.columns if df_user_transactions[var].dtypes!='O' and 'date' not in var and var!='is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "df_user_transactions['amount_gbp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions.boxplot(column = ['amount_gbp']) # Box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few transactions where amounts are significantly higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal variables\n",
    "<a id=\"temvar\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables that contain date information\n",
    "date_vars = [var for var in df_user_transactions.columns if 'date' in var]\n",
    "\n",
    "date_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook(Step2_FeatureEngineering) I tried to create some new features from these raw variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables\n",
    "<a id=\"catvar\"></a>\n",
    "\n",
    "Let's go ahead and find which variables are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorical variables\n",
    "\n",
    "cat_vars = [var for var in df_user_transactions.columns if df_user_transactions[var].dtypes=='O' and 'date' not in var]\n",
    "\n",
    "print('Number of categorical variables: ', len(cat_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualise the discrete variables\n",
    "df_user_transactions[cat_vars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of labels: cardinality\n",
    "\n",
    "Let's evaluate how many different categories are present in each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    print(var, 'has',len(df_user_transactions[var].unique()), ' categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that transacition_id and user_id has significantly high dimensions, we don't consider them while building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_categorical(df, var):\n",
    "    \"\"\"\n",
    "    Plotting the distribution of categorical variables.\n",
    "    \n",
    "    \"\"\"\n",
    "    if var not in ['transaction_id','user_id']:\n",
    "        df[df['is_fraud'] == 1].groupby(var).count()[\"is_fraud\"].plot(kind = \"bar\",color='green')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['type','state','country']:\n",
    "    analyse_categorical(df_user_transactions, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots we can observe the following\n",
    " -  Fraud transactions are happening more through TOP-UP( while receiving money externally into a Revolut account) followed by a TRANSFER(sending money externally into a bank account) types.\n",
    " -  Fraud transactions are happening more in Great Britain, France and Italy.\n",
    " -  Most of the feaud transactions are completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But from these we cannout deduce the conclusions as it might be the case that most of the transactions are happening through TOP-UP and hence the number of frauds are high in that. So lets compare the percentage of non-fradulent vs fradulent transactions for each of these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_distribution(df,var):\n",
    "    \"\"\"\n",
    "    Plotting the percentage distrubution of each variable.\n",
    "    \"\"\"\n",
    "    counter = df.groupby(var)['is_fraud'].value_counts().unstack()\n",
    "    percentage_dist = 100 * counter.divide(counter.sum(axis = 1), axis = 0)\n",
    "    percentage_dist = percentage_dist[percentage_dist> 0]\n",
    "    ax = percentage_dist.plot.bar(stacked=True,rot = 0,figsize = (15,5))\n",
    "    plt.legend(bbox_to_anchor=(0, 1), loc='upper right', ncol=1)\n",
    "    sns.set(font_scale=1)\n",
    "    for p in ax.patches:\n",
    "        width, height = p.get_width(), p.get_height()\n",
    "        x, y = p.get_xy() \n",
    "        ax.text(x+width/2, \n",
    "                y+height/2, \n",
    "                '{:.2f} %'.format(height), \n",
    "                horizontalalignment='center', \n",
    "                verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['type','state']:\n",
    "    percentage_distribution(df_user_transactions, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph's we can infer that percentage of feaud transactions are high in 'ATM' and 'TRANSFER' category compared to 'TOP-UP'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse 'country' variable in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}%'.format\n",
    "counter = df_user_transactions.groupby('country')['is_fraud'].value_counts().unstack()\n",
    "#calculate the % for each group \n",
    "percentage_dist = 100 * counter.divide(counter.sum(axis = 1), axis = 0)\n",
    "percentage_dist[percentage_dist[1]>0].sort_values(1,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we can infer that countries 'GP'(Guadeloupe),'IT'(Italy),'RE'(Reunion),'FR'(France),'NL'(Holland),'GB'(Great Britain),'DE'(Germany) have the highest fraud rate compared to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse 'country' variable in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}%'.format\n",
    "counter = df_user_transactions.groupby('currency')['is_fraud'].value_counts().unstack()\n",
    "#calculate the % for each group\n",
    "percentage_dist = 100 * counter.divide(counter.sum(axis = 1), axis = 0)\n",
    "percentage_dist[percentage_dist[1]>0.1].sort_values(1,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we can infer that transactions which are happening in currencies 'XOF','GBP','MDL','AED','MAD' have high fraud rate compared to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare labels:\n",
    "<a id=\"rarelab\"></a>\n",
    "\n",
    "Let's go ahead and investigate now if there are labels that are present only in a small number of transactions. In the next section I discussed how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "def analyse_rare_labels(df, var, rare_perc):\n",
    "    df = df.copy()\n",
    "    tmp = df.groupby(var)['is_fraud'].count() / len(df)\n",
    "    return tmp[tmp<rare_perc]\n",
    "\n",
    "for var in cat_vars:\n",
    "    if var not in ['transaction_id','user_id']:\n",
    "        print(analyse_rare_labels(df_user_transactions, var, 0.0001))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "\n",
    "https://stats.stackexchange.com/questions/384833/adjusting-probability-threshold-for-sklearns-logistic-regression-model\n",
    "\n",
    "https://github.com/trainindata/deploying-machine-learning-models\n",
    "\n",
    "https://medium.com/datadriveninvestor/rethinking-the-right-metrics-for-fraud-detection-4edfb629c423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
